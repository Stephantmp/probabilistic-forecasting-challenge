{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6bfd3ae6-0e5e-4f78-9e9f-e2cc688bdee2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-18T16:19:27.562517Z",
     "start_time": "2023-11-18T16:19:27.490832Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import requests\n",
    "from tqdm import tqdm\n",
    "\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dff0f0d8-9316-4510-8e60-b12a0e9ac253",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-18T16:19:27.570344Z",
     "start_time": "2023-11-18T16:19:27.495050Z"
    }
   },
   "outputs": [],
   "source": [
    "from functions import get_energy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/256 [00:00<?, ?it/s]/Users/stephantimpe/PycharmProjects/probabilistic-forecasting-challenge/functions/get_energy.py:28: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  energydata = pd.concat([energydata, pd.DataFrame(rawdata, columns=col_names)])\n",
      "100%|██████████| 256/256 [00:27<00:00,  9.19it/s]\n"
     ]
    }
   ],
   "source": [
    "df=get_energy.get()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-18T16:19:55.533619Z",
     "start_time": "2023-11-18T16:19:27.498210Z"
    }
   },
   "id": "ae334634c9012794"
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "data": {
      "text/plain": "                       gesamt  month  hour  month_2  month_3  month_4  \\\ndate_time                                                               \n2018-12-24 00:00:00  42.02925     12     0    False    False    False   \n2018-12-24 01:00:00  39.61025     12     1    False    False    False   \n2018-12-24 02:00:00  39.13875     12     2    False    False    False   \n2018-12-24 03:00:00  39.42100     12     3    False    False    False   \n2018-12-24 04:00:00  40.74775     12     4    False    False    False   \n\n                     month_5  month_6  month_7  month_8  ...  hour_14  \\\ndate_time                                                ...            \n2018-12-24 00:00:00    False    False    False    False  ...    False   \n2018-12-24 01:00:00    False    False    False    False  ...    False   \n2018-12-24 02:00:00    False    False    False    False  ...    False   \n2018-12-24 03:00:00    False    False    False    False  ...    False   \n2018-12-24 04:00:00    False    False    False    False  ...    False   \n\n                     hour_15  hour_16  hour_17  hour_18  hour_19  hour_20  \\\ndate_time                                                                   \n2018-12-24 00:00:00    False    False    False    False    False    False   \n2018-12-24 01:00:00    False    False    False    False    False    False   \n2018-12-24 02:00:00    False    False    False    False    False    False   \n2018-12-24 03:00:00    False    False    False    False    False    False   \n2018-12-24 04:00:00    False    False    False    False    False    False   \n\n                     hour_21  hour_22  hour_23  \ndate_time                                       \n2018-12-24 00:00:00    False    False    False  \n2018-12-24 01:00:00    False    False    False  \n2018-12-24 02:00:00    False    False    False  \n2018-12-24 03:00:00    False    False    False  \n2018-12-24 04:00:00    False    False    False  \n\n[5 rows x 37 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>gesamt</th>\n      <th>month</th>\n      <th>hour</th>\n      <th>month_2</th>\n      <th>month_3</th>\n      <th>month_4</th>\n      <th>month_5</th>\n      <th>month_6</th>\n      <th>month_7</th>\n      <th>month_8</th>\n      <th>...</th>\n      <th>hour_14</th>\n      <th>hour_15</th>\n      <th>hour_16</th>\n      <th>hour_17</th>\n      <th>hour_18</th>\n      <th>hour_19</th>\n      <th>hour_20</th>\n      <th>hour_21</th>\n      <th>hour_22</th>\n      <th>hour_23</th>\n    </tr>\n    <tr>\n      <th>date_time</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2018-12-24 00:00:00</th>\n      <td>42.02925</td>\n      <td>12</td>\n      <td>0</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>...</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>2018-12-24 01:00:00</th>\n      <td>39.61025</td>\n      <td>12</td>\n      <td>1</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>...</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>2018-12-24 02:00:00</th>\n      <td>39.13875</td>\n      <td>12</td>\n      <td>2</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>...</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>2018-12-24 03:00:00</th>\n      <td>39.42100</td>\n      <td>12</td>\n      <td>3</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>...</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>2018-12-24 04:00:00</th>\n      <td>40.74775</td>\n      <td>12</td>\n      <td>4</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>...</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 37 columns</p>\n</div>"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-18T16:20:36.534274Z",
     "start_time": "2023-11-18T16:20:36.523636Z"
    }
   },
   "id": "a01887cd9a82c432"
  },
  {
   "cell_type": "markdown",
   "id": "791b084f-f7ec-4a4a-9947-f292dfcddf4c",
   "metadata": {},
   "source": [
    "Define weekday column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a8b96cb2-ec82-433d-9c54-040d0499ca57",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-18T16:19:55.544215Z",
     "start_time": "2023-11-18T16:19:55.541798Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "#df[\"time\"] = df.index.strftime(\"%H:%M\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2cf1b27-c033-48a9-8758-ca05bfe91ed8",
   "metadata": {},
   "source": [
    "Lead times are"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ffc6169f-d45e-42b1-a0c0-a6e30c8cbec6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-18T16:19:55.551929Z",
     "start_time": "2023-11-18T16:19:55.545310Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "[36, 40, 44, 60, 64, 68]"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "horizons_def = [36, 40, 44, 60, 64, 68]#[24 + 12*i for i in range(5)]\n",
    "horizons_def"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1cf8917-68b4-4a03-b196-83915cabcb64",
   "metadata": {},
   "source": [
    "Adapt horzions so they actually fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ee0221c6-eb42-43de-8ec0-4aa2fd1519bc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-18T16:19:55.586214Z",
     "start_time": "2023-11-18T16:19:55.550957Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "[37, 41, 45, 61, 65, 69]"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "horizons = [h+1 for h in horizons_def]\n",
    "horizons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8a4b5b1f-f4a7-45fd-973d-a691a601b2cb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-18T16:19:55.586526Z",
     "start_time": "2023-11-18T16:19:55.555489Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_date_from_horizon(last_ts, horizon):\n",
    "    return last_ts + pd.DateOffset(hours=horizon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "564d7433-a811-40e5-a9ea-2e837b2b2a02",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-18T16:19:55.629537Z",
     "start_time": "2023-11-18T16:19:55.560058Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "Timestamp('2023-11-18 16:00:00')"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LAST_IDX = -1\n",
    "LAST_DATE = df.iloc[LAST_IDX].name\n",
    "LAST_DATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thursday of the current week: 2023-11-23 00:00:00\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Get the current date\n",
    "current_date = datetime.now()\n",
    "\n",
    "# Calculate the number of days to add or subtract to get to Thursday\n",
    "# In Python's datetime module, Monday is 0 and Sunday is 6\n",
    "days_until_thursday = 3 - current_date.weekday()  # 3 represents Thursday\n",
    "\n",
    "# If it's already past Thursday, calculate for the next Thursday\n",
    "if days_until_thursday < 0:\n",
    "    days_until_thursday += 7\n",
    "\n",
    "# Get the Thursday of the current week\n",
    "thursday_of_current_week = current_date + timedelta(days=days_until_thursday)\n",
    "\n",
    "# To set the time to 00:00, replace the hour, minute, second, and microsecond\n",
    "thursday_of_current_week = thursday_of_current_week.replace(hour=0, minute=0, second=0, microsecond=0)\n",
    "\n",
    "print(\"Thursday of the current week:\", thursday_of_current_week)\n",
    "LAST_DATE=thursday_of_current_week\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-18T16:19:55.630326Z",
     "start_time": "2023-11-18T16:19:55.566133Z"
    }
   },
   "id": "9dc06427dfc12345"
  },
  {
   "cell_type": "markdown",
   "id": "51214044-60af-4d25-a508-03c0a16787bc",
   "metadata": {},
   "source": [
    "Get time and date that correspond to the lead times (starting at the last observation in our data which should be the respective thursday 0:00)  \n",
    "*Attention*: if the last timestamp in the data is not thursday 0:00, you have to adjust your lead times accordingly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4e0da017-d3b4-4cde-b373-63213b42ebc0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-18T16:19:55.630699Z",
     "start_time": "2023-11-18T16:19:55.570774Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "[Timestamp('2023-11-24 13:00:00'),\n Timestamp('2023-11-24 17:00:00'),\n Timestamp('2023-11-24 21:00:00'),\n Timestamp('2023-11-25 13:00:00'),\n Timestamp('2023-11-25 17:00:00'),\n Timestamp('2023-11-25 21:00:00')]"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "horizon_date = [get_date_from_horizon(LAST_DATE, h) for h in horizons]\n",
    "horizon_date"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dcf62b9-a0ba-4582-9f83-ee24aadb0223",
   "metadata": {},
   "source": [
    "quantile levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bf3ae619-5bdc-4c66-8137-4daa880ce9c7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-18T16:19:55.630928Z",
     "start_time": "2023-11-18T16:19:55.578461Z"
    }
   },
   "outputs": [],
   "source": [
    "tau = [.025, .25, .5, .75, .975]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8e5ef128-ba07-497d-ab2b-1c7599e86bd0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-18T16:19:55.631046Z",
     "start_time": "2023-11-18T16:19:55.580823Z"
    }
   },
   "outputs": [],
   "source": [
    "#rows correspond to horizon, columns to quantile level\n",
    "pred_baseline = np.zeros((6,5))"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Seasonal regression"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7a486092d6a17ef"
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "#seasonal regression\n",
    "# Create dummy variables for months and hours\n",
    "df['month'] = df.index.month\n",
    "df['hour'] = df.index.hour\n",
    "\n",
    "# Get dummies for months and hours, excluding the first month and hour to avoid multicollinearity\n",
    "month_dummies = pd.get_dummies(df['month'], prefix='month', drop_first=True)\n",
    "hour_dummies = pd.get_dummies(df['hour'], prefix='hour', drop_first=True)\n",
    "\n",
    "# Join the dummies with the original DataFrame\n",
    "df = df.join(month_dummies).join(hour_dummies)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-18T16:19:55.658782Z",
     "start_time": "2023-11-18T16:19:55.586650Z"
    }
   },
   "id": "5d01da2b5cf92c34"
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gesamt      float64\n",
      "month         int32\n",
      "hour          int32\n",
      "month_2        bool\n",
      "month_3        bool\n",
      "month_4        bool\n",
      "month_5        bool\n",
      "month_6        bool\n",
      "month_7        bool\n",
      "month_8        bool\n",
      "month_9        bool\n",
      "month_10       bool\n",
      "month_11       bool\n",
      "month_12       bool\n",
      "hour_1         bool\n",
      "hour_2         bool\n",
      "hour_3         bool\n",
      "hour_4         bool\n",
      "hour_5         bool\n",
      "hour_6         bool\n",
      "hour_7         bool\n",
      "hour_8         bool\n",
      "hour_9         bool\n",
      "hour_10        bool\n",
      "hour_11        bool\n",
      "hour_12        bool\n",
      "hour_13        bool\n",
      "hour_14        bool\n",
      "hour_15        bool\n",
      "hour_16        bool\n",
      "hour_17        bool\n",
      "hour_18        bool\n",
      "hour_19        bool\n",
      "hour_20        bool\n",
      "hour_21        bool\n",
      "hour_22        bool\n",
      "hour_23        bool\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "df\n",
    "print(df.dtypes)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-18T16:19:55.715625Z",
     "start_time": "2023-11-18T16:19:55.604353Z"
    }
   },
   "id": "8eee6b107e342a00"
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                 gesamt   R-squared:                       0.579\n",
      "Model:                            OLS   Adj. R-squared:                  0.579\n",
      "Method:                 Least Squares   F-statistic:                     1738.\n",
      "Date:                Sat, 18 Nov 2023   Prob (F-statistic):               0.00\n",
      "Time:                        17:19:56   Log-Likelihood:            -1.4038e+05\n",
      "No. Observations:               42977   AIC:                         2.808e+05\n",
      "Df Residuals:                   42942   BIC:                         2.811e+05\n",
      "Df Model:                          34                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const         52.0263      0.180    289.165      0.000      51.674      52.379\n",
      "month_2        0.3876      0.151      2.571      0.010       0.092       0.683\n",
      "month_3       -2.5915      0.147    -17.613      0.000      -2.880      -2.303\n",
      "month_4       -6.9745      0.148    -47.011      0.000      -7.265      -6.684\n",
      "month_5       -8.4816      0.147    -57.644      0.000      -8.770      -8.193\n",
      "month_6       -8.7639      0.148    -59.073      0.000      -9.055      -8.473\n",
      "month_7       -8.3506      0.147    -56.754      0.000      -8.639      -8.062\n",
      "month_8       -9.2760      0.147    -63.043      0.000      -9.564      -8.988\n",
      "month_9       -7.5371      0.148    -50.804      0.000      -7.828      -7.246\n",
      "month_10      -5.2939      0.147    -35.979      0.000      -5.582      -5.005\n",
      "month_11      -2.2509      0.152    -14.840      0.000      -2.548      -1.954\n",
      "month_12      -3.5118      0.153    -22.891      0.000      -3.813      -3.211\n",
      "hour_1        -1.7026      0.212     -8.029      0.000      -2.118      -1.287\n",
      "hour_2        -2.5751      0.212    -12.144      0.000      -2.991      -2.159\n",
      "hour_3        -2.5036      0.212    -11.807      0.000      -2.919      -2.088\n",
      "hour_4        -1.6044      0.212     -7.566      0.000      -2.020      -1.189\n",
      "hour_5         0.6721      0.212      3.170      0.002       0.257       1.088\n",
      "hour_6         5.6279      0.212     26.540      0.000       5.212       6.044\n",
      "hour_7         9.9372      0.212     46.862      0.000       9.522      10.353\n",
      "hour_8        12.8814      0.212     60.746      0.000      12.466      13.297\n",
      "hour_9        14.3706      0.212     67.769      0.000      13.955      14.786\n",
      "hour_10       15.6030      0.212     73.581      0.000      15.187      16.019\n",
      "hour_11       16.6784      0.212     78.652      0.000      16.263      17.094\n",
      "hour_12       16.2937      0.212     76.838      0.000      15.878      16.709\n",
      "hour_13       15.0709      0.212     71.071      0.000      14.655      15.486\n",
      "hour_14       13.7210      0.212     64.706      0.000      13.305      14.137\n",
      "hour_15       12.9055      0.212     60.860      0.000      12.490      13.321\n",
      "hour_16       12.4979      0.212     58.938      0.000      12.082      12.914\n",
      "hour_17       13.5377      0.212     63.833      0.000      13.122      13.953\n",
      "hour_18       14.1128      0.212     66.544      0.000      13.697      14.528\n",
      "hour_19       13.4890      0.212     63.603      0.000      13.073      13.905\n",
      "hour_20       11.1175      0.212     52.421      0.000      10.702      11.533\n",
      "hour_21        8.5918      0.212     40.512      0.000       8.176       9.007\n",
      "hour_22        6.1590      0.212     29.041      0.000       5.743       6.575\n",
      "hour_23        2.7250      0.212     12.849      0.000       2.309       3.141\n",
      "==============================================================================\n",
      "Omnibus:                     2358.359   Durbin-Watson:                   0.049\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             2762.909\n",
      "Skew:                          -0.608   Prob(JB):                         0.00\n",
      "Kurtosis:                       3.253   Cond. No.                         25.9\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    },
    {
     "data": {
      "text/plain": "'quantile reg'"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#seasonal regression\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# Define the independent variables (X) and the dependent variable (y)\n",
    "# Exclude the original 'month' and 'hour' columns to avoid multicollinearity\n",
    "exclude_columns = ['gesamt', 'month', 'hour']\n",
    "X = df[[col for col in df.columns if col not in exclude_columns]]\n",
    "y = df['gesamt']\n",
    "X = X.apply(pd.to_numeric)\n",
    "y = y.apply(pd.to_numeric)\n",
    "\n",
    "for column in X.columns:\n",
    "    X[column] = X[column].astype(int)\n",
    "\n",
    "\n",
    "# Add a constant to the model (for the intercept)\n",
    "X = sm.add_constant(X)\n",
    "\n",
    "# Fit the model\n",
    "model = sm.OLS(y, X).fit()\n",
    "\n",
    "# Print out the statistics\n",
    "print(model.summary())\n",
    "'quantile reg'"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-18T16:19:57.026271Z",
     "start_time": "2023-11-18T16:19:55.607668Z"
    }
   },
   "id": "cf58f17ff1c61753"
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'forecast_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[21], line 4\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mpandas\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mpd\u001B[39;00m\n\u001B[1;32m      2\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mstatsmodels\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mapi\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01msm\u001B[39;00m\n\u001B[0;32m----> 4\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mShape of forecast_df:\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[43mforecast_df\u001B[49m\u001B[38;5;241m.\u001B[39mshape)\n\u001B[1;32m      5\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mShape of X:\u001B[39m\u001B[38;5;124m\"\u001B[39m, X\u001B[38;5;241m.\u001B[39mshape)\n\u001B[1;32m      9\u001B[0m \u001B[38;5;66;03m# Assuming horizon_date is a list of pandas Timestamps\u001B[39;00m\n",
      "\u001B[0;31mNameError\u001B[0m: name 'forecast_df' is not defined"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "\n",
    "print(\"Shape of forecast_df:\", forecast_df.shape)\n",
    "print(\"Shape of X:\", X.shape)\n",
    "\n",
    "\n",
    "\n",
    "# Assuming horizon_date is a list of pandas Timestamps\n",
    "horizon_dates = [pd.Timestamp('2023-11-17 13:00:00'),\n",
    "                 pd.Timestamp('2023-11-17 17:00:00'),\n",
    "                 pd.Timestamp('2023-11-17 21:00:00'),\n",
    "                 pd.Timestamp('2023-11-18 13:00:00'),\n",
    "                 pd.Timestamp('2023-11-18 17:00:00'),\n",
    "                 pd.Timestamp('2023-11-18 21:00:00')]\n",
    "\n",
    "predictions = []\n",
    "\n",
    "\n",
    "\n",
    "# Create a new DataFrame for the forecast\n",
    "forecast_df = pd.DataFrame({'date_time': horizon_dates})\n",
    "print(forecast_df)\n",
    "# Extract and one-hot encode month and hour from the date_time\n",
    "forecast_df['month'] = forecast_df['date_time'].dt.month\n",
    "forecast_df['hour'] = forecast_df['date_time'].dt.hour\n",
    "forecast_df = forecast_df.join(pd.get_dummies(forecast_df['month'], prefix='month', drop_first=True))\n",
    "forecast_df = forecast_df.join(pd.get_dummies(forecast_df['hour'], prefix='hour', drop_first=True))\n",
    "\n",
    "# Drop the original month and hour columns\n",
    "forecast_df.drop(['month', 'hour'], axis=1, inplace=True)\n",
    "\n",
    "# Add constant and weekday columns\n",
    "forecast_df['const'] = 1.0\n",
    "forecast_df['weekday'] = forecast_df['date_time'].dt.dayofweek\n",
    "\n",
    "# Ensure all columns in X are also in forecast_df\n",
    "for col in X.columns:\n",
    "    if col not in forecast_df.columns:\n",
    "        forecast_df[col] = 0\n",
    "\n",
    "# Reorder columns to match X\n",
    "forecast_df = forecast_df[X.columns]\n",
    "\n",
    "# Now forecast_df is ready for prediction\n",
    "# Drop the first column if it's redundant\n",
    "#forecast_df.drop(forecast_df.columns[0], axis=1, inplace=True)\n",
    "\n",
    "print(forecast_df)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-18T16:19:57.550038Z",
     "start_time": "2023-11-18T16:19:57.002721Z"
    }
   },
   "id": "de04f201a0fbf085"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Assuming horizon_dates is a list of pandas Timestamps\n",
    "horizon_dates = [pd.Timestamp('2023-11-17 13:00:00'),\n",
    "                 pd.Timestamp('2023-11-17 17:00:00'),\n",
    "                 pd.Timestamp('2023-11-17 21:00:00'),\n",
    "                 pd.Timestamp('2023-11-18 13:00:00'),\n",
    "                 pd.Timestamp('2023-11-18 17:00:00'),\n",
    "                 pd.Timestamp('2023-11-18 21:00:00')]\n",
    "\n",
    "# Create a new DataFrame for the forecast\n",
    "forecast_df = pd.DataFrame({'date_time': horizon_dates})\n",
    "# Extract and one-hot encode month and hour from the date_time\n",
    "forecast_df['month'] = forecast_df['date_time'].dt.month\n",
    "forecast_df['hour'] = forecast_df['date_time'].dt.hour\n",
    "forecast_df = forecast_df.join(pd.get_dummies(forecast_df['month'], prefix='month', drop_first=True))\n",
    "forecast_df = forecast_df.join(pd.get_dummies(forecast_df['hour'], prefix='hour', drop_first=True))\n",
    "\n",
    "# Drop the original month and hour columns\n",
    "forecast_df.drop(['month', 'hour'], axis=1, inplace=True)\n",
    "\n",
    "# Add constant and weekday columns\n",
    "forecast_df['const'] = 1.0\n",
    "forecast_df['weekday'] = forecast_df['date_time'].dt.dayofweek\n",
    "\n",
    "# Ensure all columns in X are also in forecast_df\n",
    "for col in X.columns:\n",
    "    if col not in forecast_df.columns and col != 'date_time':\n",
    "        forecast_df[col] = 0\n",
    "\n",
    "# Reorder columns to match X (excluding date_time)\n",
    "forecast_columns = [col for col in X.columns if col != 'date_time']\n",
    "forecast_df = forecast_df[['date_time'] + forecast_columns]\n",
    "\n",
    "# Now forecast_df is ready for prediction\n",
    "# Drop the date_time column for prediction\n",
    "forecast_df_for_prediction = forecast_df.drop('date_time', axis=1)\n",
    "\n",
    "# Make predictions\n",
    "predictions = model.predict(forecast_df_for_prediction)\n",
    "\n",
    "# Combine predictions with date_times\n",
    "forecast_df['prediction'] = predictions\n",
    "print(forecast_df[['date_time', 'prediction']])\n",
    "forecast_df\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-18T16:19:57.551817Z",
     "start_time": "2023-11-18T16:19:57.550455Z"
    }
   },
   "id": "cffd5957a3fe89e5"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-18T16:19:57.553169Z",
     "start_time": "2023-11-18T16:19:57.552228Z"
    }
   },
   "id": "f597869925e046e9"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "predictions"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-18T16:19:57.553761Z"
    }
   },
   "id": "c5028ea49ea1e75f"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6033e162-aecf-4e8c-a143-28446cffab0f",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-18T16:19:57.555308Z"
    }
   },
   "outputs": [],
   "source": [
    "#baseline\n",
    "last_t = 100\n",
    "\n",
    "for i,d in enumerate(horizon_date):\n",
    "    \n",
    "    weekday = d.weekday()\n",
    "    hour = d.hour\n",
    "    \n",
    "    df_tmp = df.iloc[:LAST_IDX]\n",
    "    \n",
    "    cond = (df_tmp.weekday == weekday) & (df_tmp.index.time == d.time())\n",
    "    \n",
    "    pred_baseline[i,:] = np.quantile(df_tmp[cond].iloc[-last_t:][\"gesamt\"], q=tau)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19935ed4-040c-4169-a28c-437a2effeede",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-18T16:19:57.557014Z"
    }
   },
   "outputs": [],
   "source": [
    "pred_baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "420cfb8d-f64b-46b1-88e3-8d5159eb88bc",
   "metadata": {},
   "source": [
    "Visually check if quantiles make sense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daf9b394-79d2-48dd-914b-8fc9a9f1a5a1",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-18T16:19:57.558445Z"
    }
   },
   "outputs": [],
   "source": [
    "x = horizons\n",
    "_ = plt.plot(x,pred_baseline, ls=\"\", marker=\"o\", c=\"black\")\n",
    "_ = plt.xticks(x, x)\n",
    "_ = plt.plot((x,x),(pred_baseline[:,0], pred_baseline[:,-1]),c='black')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ee8c6fe-43c9-4a71-b8f0-300a382f59c6",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-18T16:19:57.559821Z"
    }
   },
   "outputs": [],
   "source": [
    "from datetime import datetime, date, timedelta\n",
    "date_str = datetime.today().strftime('%Y%m%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6024fd0b-f3d5-40f4-81cd-5d2d6f5d4237",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-18T16:19:57.560772Z"
    }
   },
   "outputs": [],
   "source": [
    "date_str = date.today() #- timedelta(days=1)\n",
    "date_str = date_str\n",
    "date_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff1ff112-6973-4e8c-be11-5705434c3416",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-18T16:19:57.561707Z"
    }
   },
   "outputs": [],
   "source": [
    "df_sub = pd.DataFrame({\n",
    "    \"forecast_date\": date_str,\n",
    "    \"target\": \"energy\",\n",
    "    \"horizon\": [str(h) + \" hour\" for h in horizons_def],\n",
    "    \"q0.025\": pred_baseline[:,0],\n",
    "    \"q0.25\": pred_baseline[:,1],\n",
    "    \"q0.5\": pred_baseline[:,2],\n",
    "    \"q0.75\": pred_baseline[:,3],\n",
    "    \"q0.975\": pred_baseline[:,4]})\n",
    "df_sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94f92f2c-859a-4094-8bb4-3249c4de4f2b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-18T16:19:57.565143Z",
     "start_time": "2023-11-18T16:19:57.562939Z"
    }
   },
   "outputs": [],
   "source": [
    "#need to change this\n",
    "PATH = \"../forecasts/\"\n",
    "date_str = date_str.strftime('%Y%m%d')\n",
    "\n",
    "df_sub.to_csv(PATH+date_str+\"_power_benchmark.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec87e79b-7c52-4b83-8848-154e90df9323",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-18T16:19:57.563966Z"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
