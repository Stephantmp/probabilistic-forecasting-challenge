{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 341,
   "id": "6bfd3ae6-0e5e-4f78-9e9f-e2cc688bdee2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-15T21:48:50.434120Z",
     "start_time": "2023-11-15T21:48:50.210175Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "id": "dff0f0d8-9316-4510-8e60-b12a0e9ac253",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-15T21:48:50.434709Z",
     "start_time": "2023-11-15T21:48:50.212787Z"
    }
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from tqdm import tqdm\n",
    "\n",
    "from datetime import datetime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "id": "6dd68c07-25ac-404f-8cb5-dd7884d9acd5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-15T21:48:50.434806Z",
     "start_time": "2023-11-15T21:48:50.218756Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_energy_data():\n",
    "\n",
    "    # get all available time stamps\n",
    "    stampsurl = \"https://www.smard.de/app/chart_data/410/DE/index_quarterhour.json\"\n",
    "    response = requests.get(stampsurl)\n",
    "    #ignore first 4 years (don't need those in the baseline and speeds the code up a bit)\n",
    "    timestamps = list(response.json()[\"timestamps\"])[4*52:]\n",
    "\n",
    " \n",
    "    col_names = ['date_time','Netzlast_Gesamt']\n",
    "    energydata = pd.DataFrame(columns=col_names)\n",
    "    \n",
    "    # loop over all available timestamps\n",
    "    for stamp in tqdm(timestamps):\n",
    "\n",
    "        dataurl = \"https://www.smard.de/app/chart_data/410/DE/410_DE_quarterhour_\" + str(stamp) + \".json\"\n",
    "        response = requests.get(dataurl)\n",
    "        rawdata = response.json()[\"series\"]\n",
    "\n",
    "        for i in range(len(rawdata)):\n",
    "\n",
    "            rawdata[i][0] = datetime.fromtimestamp(int(str(rawdata[i][0])[:10])).strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "        energydata = pd.concat([energydata, pd.DataFrame(rawdata, columns=col_names)])\n",
    "\n",
    "    energydata = energydata.dropna()\n",
    "    energydata[\"date_time\"] = pd.to_datetime(energydata.date_time)\n",
    "    #set date_time as index\n",
    "    energydata.set_index(\"date_time\", inplace=True)\n",
    "    #resample\n",
    "    energydata = energydata.resample(\"1h\", label = \"left\").sum()\n",
    "\n",
    "    return energydata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "id": "8f77a2e8-851a-4969-8b54-a1d525137e79",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-15T21:49:19.394990Z",
     "start_time": "2023-11-15T21:48:50.223765Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/256 [00:00<?, ?it/s]/var/folders/y3/h1kjcg6j0wj3crmk4m1ff0380000gn/T/ipykernel_86472/2942256061.py:24: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  energydata = pd.concat([energydata, pd.DataFrame(rawdata, columns=col_names)])\n",
      "100%|██████████| 256/256 [00:28<00:00,  8.85it/s]\n"
     ]
    }
   ],
   "source": [
    "df = get_energy_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "id": "6da4b0b2-5c5d-47a3-be0e-03115f29f19d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-15T21:49:19.410839Z",
     "start_time": "2023-11-15T21:49:19.402679Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "                     Netzlast_Gesamt\ndate_time                           \n2018-12-24 00:00:00         42029.25\n2018-12-24 01:00:00         39610.25\n2018-12-24 02:00:00         39138.75\n2018-12-24 03:00:00         39421.00\n2018-12-24 04:00:00         40747.75",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Netzlast_Gesamt</th>\n    </tr>\n    <tr>\n      <th>date_time</th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2018-12-24 00:00:00</th>\n      <td>42029.25</td>\n    </tr>\n    <tr>\n      <th>2018-12-24 01:00:00</th>\n      <td>39610.25</td>\n    </tr>\n    <tr>\n      <th>2018-12-24 02:00:00</th>\n      <td>39138.75</td>\n    </tr>\n    <tr>\n      <th>2018-12-24 03:00:00</th>\n      <td>39421.00</td>\n    </tr>\n    <tr>\n      <th>2018-12-24 04:00:00</th>\n      <td>40747.75</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 345,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d12b8fc-a35a-411f-b87a-72f764275690",
   "metadata": {},
   "source": [
    "Rename column for convenience"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "id": "da3ff9bc-063a-42ae-895c-1a91a2fcde28",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-15T21:49:19.412616Z",
     "start_time": "2023-11-15T21:49:19.407382Z"
    }
   },
   "outputs": [],
   "source": [
    "df = df.rename(columns={\"Netzlast_Gesamt\": \"gesamt\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f06f031-1a45-4b03-862f-9cbdae802220",
   "metadata": {},
   "source": [
    "Rescale Netzlast so it fits requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "id": "728f7dd1-9556-4974-a8bc-51e701372ad0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-15T21:49:19.442962Z",
     "start_time": "2023-11-15T21:49:19.412757Z"
    }
   },
   "outputs": [],
   "source": [
    "df['gesamt'] = df['gesamt'] / 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f31220b-b84d-44b1-8201-29473e1c83ac",
   "metadata": {},
   "source": [
    "Check dtypes and if columns contain and missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "id": "1d362a66-6898-454f-a540-3f5773d85974",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-15T21:49:19.444288Z",
     "start_time": "2023-11-15T21:49:19.417295Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "gesamt    float64\ndtype: object"
     },
     "execution_count": 348,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "id": "c293fdd7-b8b5-45ec-9319-c514bc25fce4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-15T21:49:19.444502Z",
     "start_time": "2023-11-15T21:49:19.421293Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "gesamt    False\ndtype: bool"
     },
     "execution_count": 349,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "791b084f-f7ec-4a4a-9947-f292dfcddf4c",
   "metadata": {},
   "source": [
    "Define weekday column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "id": "a8b96cb2-ec82-433d-9c54-040d0499ca57",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-15T21:49:19.490339Z",
     "start_time": "2023-11-15T21:49:19.427280Z"
    }
   },
   "outputs": [],
   "source": [
    "df[\"weekday\"] = df.index.weekday #Monday=0, Sunday=6\n",
    "#df[\"time\"] = df.index.strftime(\"%H:%M\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2cf1b27-c033-48a9-8758-ca05bfe91ed8",
   "metadata": {},
   "source": [
    "Lead times are"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "id": "ffc6169f-d45e-42b1-a0c0-a6e30c8cbec6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-15T21:49:19.490744Z",
     "start_time": "2023-11-15T21:49:19.433239Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "[36, 40, 44, 60, 64, 68]"
     },
     "execution_count": 351,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "horizons_def = [36, 40, 44, 60, 64, 68]#[24 + 12*i for i in range(5)]\n",
    "horizons_def"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1cf8917-68b4-4a03-b196-83915cabcb64",
   "metadata": {},
   "source": [
    "Adapt horzions so they actually fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "id": "ee0221c6-eb42-43de-8ec0-4aa2fd1519bc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-15T21:49:19.490882Z",
     "start_time": "2023-11-15T21:49:19.437871Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "[37, 41, 45, 61, 65, 69]"
     },
     "execution_count": 352,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "horizons = [h+1 for h in horizons_def]\n",
    "horizons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "id": "8a4b5b1f-f4a7-45fd-973d-a691a601b2cb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-15T21:49:19.524513Z",
     "start_time": "2023-11-15T21:49:19.442167Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_date_from_horizon(last_ts, horizon):\n",
    "    return last_ts + pd.DateOffset(hours=horizon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "id": "564d7433-a811-40e5-a9ea-2e837b2b2a02",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-15T21:49:19.528405Z",
     "start_time": "2023-11-15T21:49:19.449417Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "Timestamp('2023-11-15 21:00:00')"
     },
     "execution_count": 354,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LAST_IDX = -1\n",
    "LAST_DATE = df.iloc[LAST_IDX].name\n",
    "LAST_DATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thursday of the current week: 2023-11-16 00:00:00\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Get the current date\n",
    "current_date = datetime.now()\n",
    "\n",
    "# Calculate the number of days to add or subtract to get to Thursday\n",
    "# In Python's datetime module, Monday is 0 and Sunday is 6\n",
    "days_until_thursday = 3 - current_date.weekday()  # 3 represents Thursday\n",
    "\n",
    "# If it's already past Thursday, calculate for the next Thursday\n",
    "if days_until_thursday < 0:\n",
    "    days_until_thursday += 7\n",
    "\n",
    "# Get the Thursday of the current week\n",
    "thursday_of_current_week = current_date + timedelta(days=days_until_thursday)\n",
    "\n",
    "# To set the time to 00:00, replace the hour, minute, second, and microsecond\n",
    "thursday_of_current_week = thursday_of_current_week.replace(hour=0, minute=0, second=0, microsecond=0)\n",
    "\n",
    "print(\"Thursday of the current week:\", thursday_of_current_week)\n",
    "LAST_DATE=thursday_of_current_week\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-15T21:49:19.528689Z",
     "start_time": "2023-11-15T21:49:19.454754Z"
    }
   },
   "id": "9dc06427dfc12345"
  },
  {
   "cell_type": "markdown",
   "id": "51214044-60af-4d25-a508-03c0a16787bc",
   "metadata": {},
   "source": [
    "Get time and date that correspond to the lead times (starting at the last observation in our data which should be the respective thursday 0:00)  \n",
    "*Attention*: if the last timestamp in the data is not thursday 0:00, you have to adjust your lead times accordingly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "id": "4e0da017-d3b4-4cde-b373-63213b42ebc0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-15T21:49:19.528844Z",
     "start_time": "2023-11-15T21:49:19.460726Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "[Timestamp('2023-11-17 13:00:00'),\n Timestamp('2023-11-17 17:00:00'),\n Timestamp('2023-11-17 21:00:00'),\n Timestamp('2023-11-18 13:00:00'),\n Timestamp('2023-11-18 17:00:00'),\n Timestamp('2023-11-18 21:00:00')]"
     },
     "execution_count": 356,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "horizon_date = [get_date_from_horizon(LAST_DATE, h) for h in horizons]\n",
    "horizon_date"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dcf62b9-a0ba-4582-9f83-ee24aadb0223",
   "metadata": {},
   "source": [
    "quantile levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "id": "bf3ae619-5bdc-4c66-8137-4daa880ce9c7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-15T21:49:19.647466Z",
     "start_time": "2023-11-15T21:49:19.463766Z"
    }
   },
   "outputs": [],
   "source": [
    "tau = [.025, .25, .5, .75, .975]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "id": "8e5ef128-ba07-497d-ab2b-1c7599e86bd0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-15T21:49:19.647794Z",
     "start_time": "2023-11-15T21:49:19.468768Z"
    }
   },
   "outputs": [],
   "source": [
    "#rows correspond to horizon, columns to quantile level\n",
    "pred_baseline = np.zeros((6,5))"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Seasonal regression"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7a486092d6a17ef"
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "outputs": [],
   "source": [
    "#seasonal regression\n",
    "# Create dummy variables for months and hours\n",
    "df['month'] = df.index.month\n",
    "df['hour'] = df.index.hour\n",
    "\n",
    "# Get dummies for months and hours, excluding the first month and hour to avoid multicollinearity\n",
    "month_dummies = pd.get_dummies(df['month'], prefix='month', drop_first=True)\n",
    "hour_dummies = pd.get_dummies(df['hour'], prefix='hour', drop_first=True)\n",
    "\n",
    "# Join the dummies with the original DataFrame\n",
    "df = df.join(month_dummies).join(hour_dummies)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-15T21:49:19.763447Z",
     "start_time": "2023-11-15T21:49:19.472590Z"
    }
   },
   "id": "5d01da2b5cf92c34"
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gesamt      float64\n",
      "weekday       int32\n",
      "month         int32\n",
      "hour          int32\n",
      "month_2        bool\n",
      "month_3        bool\n",
      "month_4        bool\n",
      "month_5        bool\n",
      "month_6        bool\n",
      "month_7        bool\n",
      "month_8        bool\n",
      "month_9        bool\n",
      "month_10       bool\n",
      "month_11       bool\n",
      "month_12       bool\n",
      "hour_1         bool\n",
      "hour_2         bool\n",
      "hour_3         bool\n",
      "hour_4         bool\n",
      "hour_5         bool\n",
      "hour_6         bool\n",
      "hour_7         bool\n",
      "hour_8         bool\n",
      "hour_9         bool\n",
      "hour_10        bool\n",
      "hour_11        bool\n",
      "hour_12        bool\n",
      "hour_13        bool\n",
      "hour_14        bool\n",
      "hour_15        bool\n",
      "hour_16        bool\n",
      "hour_17        bool\n",
      "hour_18        bool\n",
      "hour_19        bool\n",
      "hour_20        bool\n",
      "hour_21        bool\n",
      "hour_22        bool\n",
      "hour_23        bool\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "df\n",
    "print(df.dtypes)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-15T21:49:19.821525Z",
     "start_time": "2023-11-15T21:49:19.490694Z"
    }
   },
   "id": "8eee6b107e342a00"
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                 gesamt   R-squared:                       0.711\n",
      "Model:                            OLS   Adj. R-squared:                  0.710\n",
      "Method:                 Least Squares   F-statistic:                     3009.\n",
      "Date:                Wed, 15 Nov 2023   Prob (F-statistic):               0.00\n",
      "Time:                        22:49:19   Log-Likelihood:            -1.3212e+05\n",
      "No. Observations:               42910   AIC:                         2.643e+05\n",
      "Df Residuals:                   42874   BIC:                         2.646e+05\n",
      "Df Model:                          35                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const         57.3840      0.154    372.333      0.000      57.082      57.686\n",
      "weekday       -1.7728      0.013   -139.593      0.000      -1.798      -1.748\n",
      "month_2        0.3785      0.125      3.028      0.002       0.133       0.623\n",
      "month_3       -2.6830      0.122    -21.990      0.000      -2.922      -2.444\n",
      "month_4       -6.9733      0.123    -56.685      0.000      -7.214      -6.732\n",
      "month_5       -8.5159      0.122    -69.798      0.000      -8.755      -8.277\n",
      "month_6       -8.8337      0.123    -71.807      0.000      -9.075      -8.593\n",
      "month_7       -8.3277      0.122    -68.256      0.000      -8.567      -8.089\n",
      "month_8       -9.3789      0.122    -76.871      0.000      -9.618      -9.140\n",
      "month_9       -7.5610      0.123    -61.462      0.000      -7.802      -7.320\n",
      "month_10      -5.2595      0.122    -43.109      0.000      -5.499      -5.020\n",
      "month_11      -2.3263      0.126    -18.394      0.000      -2.574      -2.078\n",
      "month_12      -3.6133      0.127    -28.404      0.000      -3.863      -3.364\n",
      "hour_1        -1.7053      0.176     -9.690      0.000      -2.050      -1.360\n",
      "hour_2        -2.5800      0.176    -14.661      0.000      -2.925      -2.235\n",
      "hour_3        -2.5103      0.176    -14.265      0.000      -2.855      -2.165\n",
      "hour_4        -1.6121      0.176     -9.161      0.000      -1.957      -1.267\n",
      "hour_5         0.6657      0.176      3.783      0.000       0.321       1.011\n",
      "hour_6         5.6187      0.176     31.928      0.000       5.274       5.964\n",
      "hour_7         9.9263      0.176     56.405      0.000       9.581      10.271\n",
      "hour_8        12.8722      0.176     73.144      0.000      12.527      13.217\n",
      "hour_9        14.3635      0.176     81.619      0.000      14.019      14.708\n",
      "hour_10       15.6001      0.176     88.645      0.000      15.255      15.945\n",
      "hour_11       16.6783      0.176     94.772      0.000      16.333      17.023\n",
      "hour_12       16.2941      0.176     92.589      0.000      15.949      16.639\n",
      "hour_13       15.0696      0.176     85.631      0.000      14.725      15.415\n",
      "hour_14       13.7186      0.176     77.954      0.000      13.374      14.064\n",
      "hour_15       12.9011      0.176     73.309      0.000      12.556      13.246\n",
      "hour_16       12.5082      0.176     71.076      0.000      12.163      12.853\n",
      "hour_17       13.5268      0.176     76.864      0.000      13.182      13.872\n",
      "hour_18       14.0992      0.176     80.117      0.000      13.754      14.444\n",
      "hour_19       13.4752      0.176     76.571      0.000      13.130      13.820\n",
      "hour_20       11.1079      0.176     63.119      0.000      10.763      11.453\n",
      "hour_21        8.5866      0.176     48.792      0.000       8.242       8.932\n",
      "hour_22        6.1589      0.176     34.992      0.000       5.814       6.504\n",
      "hour_23        2.7267      0.176     15.492      0.000       2.382       3.072\n",
      "==============================================================================\n",
      "Omnibus:                     2637.505   Durbin-Watson:                   0.096\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             5138.929\n",
      "Skew:                          -0.443   Prob(JB):                         0.00\n",
      "Kurtosis:                       4.445   Cond. No.                         90.9\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "#seasonal regression\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# Define the independent variables (X) and the dependent variable (y)\n",
    "# Exclude the original 'month' and 'hour' columns to avoid multicollinearity\n",
    "exclude_columns = ['gesamt', 'month', 'hour']\n",
    "X = df[[col for col in df.columns if col not in exclude_columns]]\n",
    "y = df['gesamt']\n",
    "X = X.apply(pd.to_numeric)\n",
    "y = y.apply(pd.to_numeric)\n",
    "\n",
    "for column in X.columns:\n",
    "    X[column] = X[column].astype(int)\n",
    "\n",
    "\n",
    "# Add a constant to the model (for the intercept)\n",
    "X = sm.add_constant(X)\n",
    "\n",
    "# Fit the model\n",
    "model = sm.OLS(y, X).fit()\n",
    "\n",
    "# Print out the statistics\n",
    "print(model.summary())\n",
    "'quantile reg'"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-15T21:49:19.935261Z",
     "start_time": "2023-11-15T21:49:19.496531Z"
    }
   },
   "id": "cf58f17ff1c61753"
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of forecast_df: (6, 36)\n",
      "Shape of X: (42910, 36)\n",
      "            date_time\n",
      "0 2023-11-17 13:00:00\n",
      "1 2023-11-17 17:00:00\n",
      "2 2023-11-17 21:00:00\n",
      "3 2023-11-18 13:00:00\n",
      "4 2023-11-18 17:00:00\n",
      "5 2023-11-18 21:00:00\n",
      "   const  weekday  month_2  month_3  month_4  month_5  month_6  month_7  \\\n",
      "0    1.0        4        0        0        0        0        0        0   \n",
      "1    1.0        4        0        0        0        0        0        0   \n",
      "2    1.0        4        0        0        0        0        0        0   \n",
      "3    1.0        5        0        0        0        0        0        0   \n",
      "4    1.0        5        0        0        0        0        0        0   \n",
      "5    1.0        5        0        0        0        0        0        0   \n",
      "\n",
      "   month_8  month_9  ...  hour_14  hour_15  hour_16  hour_17  hour_18  \\\n",
      "0        0        0  ...        0        0        0    False        0   \n",
      "1        0        0  ...        0        0        0     True        0   \n",
      "2        0        0  ...        0        0        0    False        0   \n",
      "3        0        0  ...        0        0        0    False        0   \n",
      "4        0        0  ...        0        0        0     True        0   \n",
      "5        0        0  ...        0        0        0    False        0   \n",
      "\n",
      "   hour_19  hour_20  hour_21  hour_22  hour_23  \n",
      "0        0        0    False        0        0  \n",
      "1        0        0    False        0        0  \n",
      "2        0        0     True        0        0  \n",
      "3        0        0    False        0        0  \n",
      "4        0        0    False        0        0  \n",
      "5        0        0     True        0        0  \n",
      "\n",
      "[6 rows x 36 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "\n",
    "print(\"Shape of forecast_df:\", forecast_df.shape)\n",
    "print(\"Shape of X:\", X.shape)\n",
    "\n",
    "\n",
    "\n",
    "# Assuming horizon_date is a list of pandas Timestamps\n",
    "horizon_dates = [pd.Timestamp('2023-11-17 13:00:00'),\n",
    "                 pd.Timestamp('2023-11-17 17:00:00'),\n",
    "                 pd.Timestamp('2023-11-17 21:00:00'),\n",
    "                 pd.Timestamp('2023-11-18 13:00:00'),\n",
    "                 pd.Timestamp('2023-11-18 17:00:00'),\n",
    "                 pd.Timestamp('2023-11-18 21:00:00')]\n",
    "\n",
    "predictions = []\n",
    "\n",
    "\n",
    "\n",
    "# Create a new DataFrame for the forecast\n",
    "forecast_df = pd.DataFrame({'date_time': horizon_dates})\n",
    "print(forecast_df)\n",
    "# Extract and one-hot encode month and hour from the date_time\n",
    "forecast_df['month'] = forecast_df['date_time'].dt.month\n",
    "forecast_df['hour'] = forecast_df['date_time'].dt.hour\n",
    "forecast_df = forecast_df.join(pd.get_dummies(forecast_df['month'], prefix='month', drop_first=True))\n",
    "forecast_df = forecast_df.join(pd.get_dummies(forecast_df['hour'], prefix='hour', drop_first=True))\n",
    "\n",
    "# Drop the original month and hour columns\n",
    "forecast_df.drop(['month', 'hour'], axis=1, inplace=True)\n",
    "\n",
    "# Add constant and weekday columns\n",
    "forecast_df['const'] = 1.0\n",
    "forecast_df['weekday'] = forecast_df['date_time'].dt.dayofweek\n",
    "\n",
    "# Ensure all columns in X are also in forecast_df\n",
    "for col in X.columns:\n",
    "    if col not in forecast_df.columns:\n",
    "        forecast_df[col] = 0\n",
    "\n",
    "# Reorder columns to match X\n",
    "forecast_df = forecast_df[X.columns]\n",
    "\n",
    "# Now forecast_df is ready for prediction\n",
    "# Drop the first column if it's redundant\n",
    "#forecast_df.drop(forecast_df.columns[0], axis=1, inplace=True)\n",
    "\n",
    "print(forecast_df)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-15T21:53:17.068637Z",
     "start_time": "2023-11-15T21:53:17.040982Z"
    }
   },
   "id": "de04f201a0fbf085"
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            date_time prediction\n",
      "0 2023-11-17 13:00:00  50.292641\n",
      "1 2023-11-17 17:00:00  63.819479\n",
      "2 2023-11-17 21:00:00  58.879266\n",
      "3 2023-11-18 13:00:00  48.519804\n",
      "4 2023-11-18 17:00:00  62.046642\n",
      "5 2023-11-18 21:00:00  57.106429\n"
     ]
    },
    {
     "data": {
      "text/plain": "            date_time  const  weekday  month_2  month_3  month_4  month_5  \\\n0 2023-11-17 13:00:00    1.0        4        0        0        0        0   \n1 2023-11-17 17:00:00    1.0        4        0        0        0        0   \n2 2023-11-17 21:00:00    1.0        4        0        0        0        0   \n3 2023-11-18 13:00:00    1.0        5        0        0        0        0   \n4 2023-11-18 17:00:00    1.0        5        0        0        0        0   \n5 2023-11-18 21:00:00    1.0        5        0        0        0        0   \n\n   month_6  month_7  month_8  ...  hour_15  hour_16  hour_17  hour_18  \\\n0        0        0        0  ...        0        0    False        0   \n1        0        0        0  ...        0        0     True        0   \n2        0        0        0  ...        0        0    False        0   \n3        0        0        0  ...        0        0    False        0   \n4        0        0        0  ...        0        0     True        0   \n5        0        0        0  ...        0        0    False        0   \n\n   hour_19  hour_20  hour_21  hour_22  hour_23  prediction  \n0        0        0    False        0        0   50.292641  \n1        0        0    False        0        0   63.819479  \n2        0        0     True        0        0   58.879266  \n3        0        0    False        0        0   48.519804  \n4        0        0    False        0        0   62.046642  \n5        0        0     True        0        0   57.106429  \n\n[6 rows x 38 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>date_time</th>\n      <th>const</th>\n      <th>weekday</th>\n      <th>month_2</th>\n      <th>month_3</th>\n      <th>month_4</th>\n      <th>month_5</th>\n      <th>month_6</th>\n      <th>month_7</th>\n      <th>month_8</th>\n      <th>...</th>\n      <th>hour_15</th>\n      <th>hour_16</th>\n      <th>hour_17</th>\n      <th>hour_18</th>\n      <th>hour_19</th>\n      <th>hour_20</th>\n      <th>hour_21</th>\n      <th>hour_22</th>\n      <th>hour_23</th>\n      <th>prediction</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2023-11-17 13:00:00</td>\n      <td>1.0</td>\n      <td>4</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>False</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>False</td>\n      <td>0</td>\n      <td>0</td>\n      <td>50.292641</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2023-11-17 17:00:00</td>\n      <td>1.0</td>\n      <td>4</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>True</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>False</td>\n      <td>0</td>\n      <td>0</td>\n      <td>63.819479</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2023-11-17 21:00:00</td>\n      <td>1.0</td>\n      <td>4</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>False</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>True</td>\n      <td>0</td>\n      <td>0</td>\n      <td>58.879266</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2023-11-18 13:00:00</td>\n      <td>1.0</td>\n      <td>5</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>False</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>False</td>\n      <td>0</td>\n      <td>0</td>\n      <td>48.519804</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2023-11-18 17:00:00</td>\n      <td>1.0</td>\n      <td>5</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>True</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>False</td>\n      <td>0</td>\n      <td>0</td>\n      <td>62.046642</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>2023-11-18 21:00:00</td>\n      <td>1.0</td>\n      <td>5</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>False</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>True</td>\n      <td>0</td>\n      <td>0</td>\n      <td>57.106429</td>\n    </tr>\n  </tbody>\n</table>\n<p>6 rows × 38 columns</p>\n</div>"
     },
     "execution_count": 369,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Assuming horizon_dates is a list of pandas Timestamps\n",
    "horizon_dates = [pd.Timestamp('2023-11-17 13:00:00'),\n",
    "                 pd.Timestamp('2023-11-17 17:00:00'),\n",
    "                 pd.Timestamp('2023-11-17 21:00:00'),\n",
    "                 pd.Timestamp('2023-11-18 13:00:00'),\n",
    "                 pd.Timestamp('2023-11-18 17:00:00'),\n",
    "                 pd.Timestamp('2023-11-18 21:00:00')]\n",
    "\n",
    "# Create a new DataFrame for the forecast\n",
    "forecast_df = pd.DataFrame({'date_time': horizon_dates})\n",
    "# Extract and one-hot encode month and hour from the date_time\n",
    "forecast_df['month'] = forecast_df['date_time'].dt.month\n",
    "forecast_df['hour'] = forecast_df['date_time'].dt.hour\n",
    "forecast_df = forecast_df.join(pd.get_dummies(forecast_df['month'], prefix='month', drop_first=True))\n",
    "forecast_df = forecast_df.join(pd.get_dummies(forecast_df['hour'], prefix='hour', drop_first=True))\n",
    "\n",
    "# Drop the original month and hour columns\n",
    "forecast_df.drop(['month', 'hour'], axis=1, inplace=True)\n",
    "\n",
    "# Add constant and weekday columns\n",
    "forecast_df['const'] = 1.0\n",
    "forecast_df['weekday'] = forecast_df['date_time'].dt.dayofweek\n",
    "\n",
    "# Ensure all columns in X are also in forecast_df\n",
    "for col in X.columns:\n",
    "    if col not in forecast_df.columns and col != 'date_time':\n",
    "        forecast_df[col] = 0\n",
    "\n",
    "# Reorder columns to match X (excluding date_time)\n",
    "forecast_columns = [col for col in X.columns if col != 'date_time']\n",
    "forecast_df = forecast_df[['date_time'] + forecast_columns]\n",
    "\n",
    "# Now forecast_df is ready for prediction\n",
    "# Drop the date_time column for prediction\n",
    "forecast_df_for_prediction = forecast_df.drop('date_time', axis=1)\n",
    "\n",
    "# Make predictions\n",
    "predictions = model.predict(forecast_df_for_prediction)\n",
    "\n",
    "# Combine predictions with date_times\n",
    "forecast_df['prediction'] = predictions\n",
    "print(forecast_df[['date_time', 'prediction']])\n",
    "forecast_df\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-15T21:59:06.374226Z",
     "start_time": "2023-11-15T21:59:06.345256Z"
    }
   },
   "id": "cffd5957a3fe89e5"
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "outputs": [
    {
     "data": {
      "text/plain": "                     const  weekday  month_2  month_3  month_4  month_5  \\\ndate_time                                                                 \n2018-12-24 00:00:00    1.0        0        0        0        0        0   \n2018-12-24 01:00:00    1.0        0        0        0        0        0   \n2018-12-24 02:00:00    1.0        0        0        0        0        0   \n2018-12-24 03:00:00    1.0        0        0        0        0        0   \n2018-12-24 04:00:00    1.0        0        0        0        0        0   \n\n                     month_6  month_7  month_8  month_9  ...  hour_14  \\\ndate_time                                                ...            \n2018-12-24 00:00:00        0        0        0        0  ...        0   \n2018-12-24 01:00:00        0        0        0        0  ...        0   \n2018-12-24 02:00:00        0        0        0        0  ...        0   \n2018-12-24 03:00:00        0        0        0        0  ...        0   \n2018-12-24 04:00:00        0        0        0        0  ...        0   \n\n                     hour_15  hour_16  hour_17  hour_18  hour_19  hour_20  \\\ndate_time                                                                   \n2018-12-24 00:00:00        0        0        0        0        0        0   \n2018-12-24 01:00:00        0        0        0        0        0        0   \n2018-12-24 02:00:00        0        0        0        0        0        0   \n2018-12-24 03:00:00        0        0        0        0        0        0   \n2018-12-24 04:00:00        0        0        0        0        0        0   \n\n                     hour_21  hour_22  hour_23  \ndate_time                                       \n2018-12-24 00:00:00        0        0        0  \n2018-12-24 01:00:00        0        0        0  \n2018-12-24 02:00:00        0        0        0  \n2018-12-24 03:00:00        0        0        0  \n2018-12-24 04:00:00        0        0        0  \n\n[5 rows x 36 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>const</th>\n      <th>weekday</th>\n      <th>month_2</th>\n      <th>month_3</th>\n      <th>month_4</th>\n      <th>month_5</th>\n      <th>month_6</th>\n      <th>month_7</th>\n      <th>month_8</th>\n      <th>month_9</th>\n      <th>...</th>\n      <th>hour_14</th>\n      <th>hour_15</th>\n      <th>hour_16</th>\n      <th>hour_17</th>\n      <th>hour_18</th>\n      <th>hour_19</th>\n      <th>hour_20</th>\n      <th>hour_21</th>\n      <th>hour_22</th>\n      <th>hour_23</th>\n    </tr>\n    <tr>\n      <th>date_time</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2018-12-24 00:00:00</th>\n      <td>1.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2018-12-24 01:00:00</th>\n      <td>1.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2018-12-24 02:00:00</th>\n      <td>1.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2018-12-24 03:00:00</th>\n      <td>1.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2018-12-24 04:00:00</th>\n      <td>1.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 36 columns</p>\n</div>"
     },
     "execution_count": 367,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-15T21:55:19.310891Z",
     "start_time": "2023-11-15T21:55:19.283645Z"
    }
   },
   "id": "f597869925e046e9"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "predictions"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-15T21:49:19.915959Z"
    }
   },
   "id": "c5028ea49ea1e75f"
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "id": "6033e162-aecf-4e8c-a143-28446cffab0f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-15T22:02:09.267174Z",
     "start_time": "2023-11-15T22:02:09.188159Z"
    }
   },
   "outputs": [],
   "source": [
    "#baseline\n",
    "last_t = 100\n",
    "\n",
    "for i,d in enumerate(horizon_date):\n",
    "    \n",
    "    weekday = d.weekday()\n",
    "    hour = d.hour\n",
    "    \n",
    "    df_tmp = df.iloc[:LAST_IDX]\n",
    "    \n",
    "    cond = (df_tmp.weekday == weekday) & (df_tmp.index.time == d.time())\n",
    "    \n",
    "    pred_baseline[i,:] = np.quantile(df_tmp[cond].iloc[-last_t:][\"gesamt\"], q=tau)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "id": "19935ed4-040c-4169-a28c-437a2effeede",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-15T22:02:10.120036Z",
     "start_time": "2023-11-15T22:02:10.102641Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "array([[51.66358125, 59.2420625 , 62.029375  , 65.577625  , 73.36360625],\n       [51.09976875, 55.669625  , 59.1605    , 64.0443125 , 72.68700625],\n       [47.7235    , 50.3398125 , 52.98975   , 56.98025   , 63.51105625],\n       [45.99123125, 49.9445625 , 51.937625  , 55.6895    , 62.02273125],\n       [44.6488625 , 47.9235    , 50.627875  , 55.8206875 , 64.4247625 ],\n       [42.2491875 , 44.67875   , 47.618625  , 50.817125  , 57.1165625 ]])"
     },
     "execution_count": 373,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "420cfb8d-f64b-46b1-88e3-8d5159eb88bc",
   "metadata": {},
   "source": [
    "Visually check if quantiles make sense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daf9b394-79d2-48dd-914b-8fc9a9f1a5a1",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-15T21:49:19.923270Z"
    }
   },
   "outputs": [],
   "source": [
    "x = horizons\n",
    "_ = plt.plot(x,pred_baseline, ls=\"\", marker=\"o\", c=\"black\")\n",
    "_ = plt.xticks(x, x)\n",
    "_ = plt.plot((x,x),(pred_baseline[:,0], pred_baseline[:,-1]),c='black')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ee8c6fe-43c9-4a71-b8f0-300a382f59c6",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-15T21:49:19.925831Z"
    }
   },
   "outputs": [],
   "source": [
    "from datetime import datetime, date, timedelta\n",
    "date_str = datetime.today().strftime('%Y%m%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6024fd0b-f3d5-40f4-81cd-5d2d6f5d4237",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-15T21:49:19.928326Z"
    }
   },
   "outputs": [],
   "source": [
    "date_str = date.today() #- timedelta(days=1)\n",
    "date_str = date_str\n",
    "date_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff1ff112-6973-4e8c-be11-5705434c3416",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-15T21:49:19.930972Z"
    }
   },
   "outputs": [],
   "source": [
    "df_sub = pd.DataFrame({\n",
    "    \"forecast_date\": date_str,\n",
    "    \"target\": \"energy\",\n",
    "    \"horizon\": [str(h) + \" hour\" for h in horizons_def],\n",
    "    \"q0.025\": pred_baseline[:,0],\n",
    "    \"q0.25\": pred_baseline[:,1],\n",
    "    \"q0.5\": pred_baseline[:,2],\n",
    "    \"q0.75\": pred_baseline[:,3],\n",
    "    \"q0.975\": pred_baseline[:,4]})\n",
    "df_sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94f92f2c-859a-4094-8bb4-3249c4de4f2b",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-15T21:49:19.933475Z"
    }
   },
   "outputs": [],
   "source": [
    "#need to change this\n",
    "PATH = \"../forecasts/\"\n",
    "date_str = date_str.strftime('%Y%m%d')\n",
    "\n",
    "df_sub.to_csv(PATH+date_str+\"_power_benchmark.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec87e79b-7c52-4b83-8848-154e90df9323",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-15T21:49:19.935011Z"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
