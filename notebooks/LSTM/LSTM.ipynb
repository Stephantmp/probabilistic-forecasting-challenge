{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-01-05T07:46:06.751553Z",
     "start_time": "2024-01-05T07:46:04.629063Z"
    }
   },
   "outputs": [],
   "source": [
    "from models.DAX import DAX_quantile_regression, DAX_baseline\n",
    "from models.energy import energy_quantile_regression\n",
    "from functions import get_energy, get_DAX, merge_submissions, check_submission\n",
    "from functions.prepare_data import split_time\n",
    "from functions.evaluation import evaluate_horizon\n",
    "from tqdm import tqdm\n",
    "from functions import evaluate_dax\n",
    "from functions import naive_ensemble\n",
    "import pandas as pd\n",
    "#import minmaxscaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from datetime import datetime, date, timedelta\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/263 [00:00<?, ?it/s]/Users/stephantimpe/PycharmProjects/probabilistic-forecasting-challenge/functions/get_energy.py:28: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  energydata = pd.concat([energydata, pd.DataFrame(rawdata, columns=col_names)])\n",
      "100%|██████████| 263/263 [00:27<00:00,  9.67it/s]\n"
     ]
    }
   ],
   "source": [
    "energydata = get_energy.get()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-05T07:46:34.166735Z",
     "start_time": "2024-01-05T07:46:06.751892Z"
    }
   },
   "id": "9ecfef8d6c7a0d3"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "                       gesamt  weekday\ndate_time                             \n2018-12-24 00:00:00  42.02925        0\n2018-12-24 01:00:00  39.61025        0\n2018-12-24 02:00:00  39.13875        0\n2018-12-24 03:00:00  39.42100        0\n2018-12-24 04:00:00  40.74775        0",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>gesamt</th>\n      <th>weekday</th>\n    </tr>\n    <tr>\n      <th>date_time</th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2018-12-24 00:00:00</th>\n      <td>42.02925</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2018-12-24 01:00:00</th>\n      <td>39.61025</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2018-12-24 02:00:00</th>\n      <td>39.13875</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2018-12-24 03:00:00</th>\n      <td>39.42100</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2018-12-24 04:00:00</th>\n      <td>40.74775</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "energydata.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-13T13:11:57.291073Z",
     "start_time": "2023-12-13T13:11:57.260865Z"
    }
   },
   "id": "3370e46bb8d4b54e"
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "4be1048b78e4f930"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Scale the data"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "20f6940a16411e67"
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "                       gesamt  weekday  gesamt_normalized\ndate_time                                                \n2018-12-24 00:00:00  42.02925        0           0.504797\n2018-12-24 01:00:00  39.61025        0           0.475743\n2018-12-24 02:00:00  39.13875        0           0.470080\n2018-12-24 03:00:00  39.42100        0           0.473470\n2018-12-24 04:00:00  40.74775        0           0.489405",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>gesamt</th>\n      <th>weekday</th>\n      <th>gesamt_normalized</th>\n    </tr>\n    <tr>\n      <th>date_time</th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2018-12-24 00:00:00</th>\n      <td>42.02925</td>\n      <td>0</td>\n      <td>0.504797</td>\n    </tr>\n    <tr>\n      <th>2018-12-24 01:00:00</th>\n      <td>39.61025</td>\n      <td>0</td>\n      <td>0.475743</td>\n    </tr>\n    <tr>\n      <th>2018-12-24 02:00:00</th>\n      <td>39.13875</td>\n      <td>0</td>\n      <td>0.470080</td>\n    </tr>\n    <tr>\n      <th>2018-12-24 03:00:00</th>\n      <td>39.42100</td>\n      <td>0</td>\n      <td>0.473470</td>\n    </tr>\n    <tr>\n      <th>2018-12-24 04:00:00</th>\n      <td>40.74775</td>\n      <td>0</td>\n      <td>0.489405</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating a DataFrame\n",
    "df = pd.DataFrame(energydata)\n",
    "\n",
    "# Normalizing the 'gesamt' column\n",
    "scaler = MinMaxScaler()\n",
    "df['gesamt_normalized'] = scaler.fit_transform(df[['gesamt']])\n",
    "\n",
    "df.head()  # Display the first few rows of the preprocessed DataFrame"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-13T13:12:58.716138Z",
     "start_time": "2023-12-13T13:12:58.699175Z"
    }
   },
   "id": "77ef1642d1cf147a"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Split the data into train and test sets"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5558ba1d1cb3ddb1"
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [
    {
     "data": {
      "text/plain": "((34859, 4), (34859, 1), (8715, 4), (8715, 1))"
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Assuming df has 'date_time' as its index and 'gesamt_normalized' as a column\n",
    "# Extracting temporal features\n",
    "df['hour'] = df.index.hour\n",
    "df['day'] = df.index.day\n",
    "df['month'] = df.index.month\n",
    "# ... add other temporal features you find relevant\n",
    "\n",
    "# Splitting the data into train and test sets chronologically\n",
    "train_size = int(len(df) * 0.8)\n",
    "train_df, test_df = df[:train_size], df[train_size:]\n",
    "\n",
    "# Selecting the features and target for training\n",
    "feature_columns = ['gesamt_normalized', 'hour', 'day', 'month'] # add other columns if needed\n",
    "train_X = train_df[feature_columns].values\n",
    "train_y = train_df['gesamt'].values.reshape(-1, 1)\n",
    "test_X = test_df[feature_columns].values\n",
    "test_y = test_df['gesamt'].values.reshape(-1, 1)\n",
    "\n",
    "# Shapes of the training and testing data\n",
    "train_X.shape, train_y.shape, test_X.shape, test_y.shape\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-13T14:02:13.811576Z",
     "start_time": "2023-12-13T14:02:13.779105Z"
    }
   },
   "id": "e1f7c33b78380fa6"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Train the LSTM model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7f22b03965ebde1d"
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-13 15:02:16.871956: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-12-13 15:02:16.874055: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-12-13 15:02:16.874870: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-12-13 15:02:17.135137: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-12-13 15:02:17.135624: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-12-13 15:02:17.136149: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-12-13 15:02:17.294087: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-12-13 15:02:17.294845: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-12-13 15:02:17.295335: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34859/34859 [==============================] - 18s 487us/step - loss: 71.6349\n",
      "Epoch 2/10\n",
      "34859/34859 [==============================] - 17s 490us/step - loss: 0.4715\n",
      "Epoch 3/10\n",
      "34859/34859 [==============================] - 17s 499us/step - loss: 0.3235\n",
      "Epoch 4/10\n",
      "34859/34859 [==============================] - 17s 480us/step - loss: 0.2340\n",
      "Epoch 5/10\n",
      "34859/34859 [==============================] - 18s 502us/step - loss: 0.2213\n",
      "Epoch 6/10\n",
      "34859/34859 [==============================] - 18s 508us/step - loss: 0.1881\n",
      "Epoch 7/10\n",
      "34859/34859 [==============================] - 19s 534us/step - loss: 0.1589\n",
      "Epoch 8/10\n",
      "34859/34859 [==============================] - 17s 474us/step - loss: 0.1624\n",
      "Epoch 9/10\n",
      "34859/34859 [==============================] - 16s 471us/step - loss: 0.1330\n",
      "Epoch 10/10\n",
      "34859/34859 [==============================] - 16s 453us/step - loss: 0.1339\n"
     ]
    },
    {
     "data": {
      "text/plain": "<keras.callbacks.History at 0x2889a0220>"
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense\n",
    "import numpy as np\n",
    "\n",
    "# Assuming you have already prepared train_X, train_y, test_X, test_y as shown before\n",
    "\n",
    "# Reshaping input data for LSTM [samples, time steps, features]\n",
    "train_X_lstm = np.reshape(train_X, (train_X.shape[0], 1, train_X.shape[1]))\n",
    "test_X_lstm = np.reshape(test_X, (test_X.shape[0], 1, test_X.shape[1]))\n",
    "\n",
    "# Designing the LSTM model\n",
    "model = Sequential()\n",
    "model.add(LSTM(50, input_shape=(train_X_lstm.shape[1], train_X_lstm.shape[2])))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "\n",
    "# Training the model\n",
    "model.fit(train_X_lstm, train_y, epochs=10, batch_size=1, verbose=1)\n",
    "\n",
    "# You can then use model.predict to make predictions on your test set\n",
    "# and evaluate the model's performance\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-13T14:05:08.355202Z",
     "start_time": "2023-12-13T14:02:16.700193Z"
    }
   },
   "id": "2ece217153a0bbd"
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "216/273 [======================>.......] - ETA: 0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-13 15:05:12.170637: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-12-13 15:05:12.171645: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-12-13 15:05:12.172098: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "273/273 [==============================] - 0s 461us/step\n",
      "273/273 [==============================] - 0s 334us/step\n",
      "273/273 [==============================] - 0s 391us/step\n",
      "273/273 [==============================] - 0s 330us/step\n",
      "273/273 [==============================] - 0s 330us/step\n",
      "273/273 [==============================] - 0s 476us/step\n",
      "273/273 [==============================] - 0s 336us/step\n",
      "273/273 [==============================] - 0s 323us/step\n",
      "273/273 [==============================] - 0s 335us/step\n",
      "273/273 [==============================] - 0s 334us/step\n",
      "273/273 [==============================] - 0s 344us/step\n",
      "273/273 [==============================] - 0s 331us/step\n",
      "273/273 [==============================] - 0s 325us/step\n",
      "273/273 [==============================] - 0s 315us/step\n",
      "273/273 [==============================] - 0s 332us/step\n",
      "273/273 [==============================] - 0s 328us/step\n",
      "273/273 [==============================] - 0s 324us/step\n",
      "273/273 [==============================] - 0s 323us/step\n",
      "273/273 [==============================] - 0s 315us/step\n",
      "273/273 [==============================] - 0s 326us/step\n",
      "273/273 [==============================] - 0s 309us/step\n",
      "273/273 [==============================] - 0s 322us/step\n",
      "273/273 [==============================] - 0s 319us/step\n",
      "273/273 [==============================] - 0s 318us/step\n",
      "273/273 [==============================] - 0s 327us/step\n",
      "273/273 [==============================] - 0s 330us/step\n",
      "273/273 [==============================] - 0s 345us/step\n",
      "273/273 [==============================] - 0s 343us/step\n",
      "273/273 [==============================] - 0s 332us/step\n",
      "273/273 [==============================] - 0s 322us/step\n",
      "273/273 [==============================] - 0s 319us/step\n",
      "273/273 [==============================] - 0s 321us/step\n",
      "273/273 [==============================] - 0s 312us/step\n",
      "273/273 [==============================] - 0s 328us/step\n",
      "273/273 [==============================] - 0s 325us/step\n",
      "273/273 [==============================] - 0s 311us/step\n",
      "273/273 [==============================] - 0s 328us/step\n",
      "273/273 [==============================] - 0s 311us/step\n",
      "273/273 [==============================] - 0s 325us/step\n",
      "273/273 [==============================] - 0s 319us/step\n",
      "273/273 [==============================] - 0s 318us/step\n",
      "273/273 [==============================] - 0s 309us/step\n",
      "273/273 [==============================] - 0s 313us/step\n",
      "273/273 [==============================] - 0s 325us/step\n",
      "273/273 [==============================] - 0s 331us/step\n",
      "273/273 [==============================] - 0s 316us/step\n",
      "273/273 [==============================] - 0s 308us/step\n",
      "273/273 [==============================] - 0s 309us/step\n",
      "273/273 [==============================] - 0s 316us/step\n",
      "273/273 [==============================] - 0s 308us/step\n",
      "273/273 [==============================] - 0s 311us/step\n",
      "273/273 [==============================] - 0s 308us/step\n",
      "273/273 [==============================] - 0s 314us/step\n",
      "273/273 [==============================] - 0s 304us/step\n",
      "273/273 [==============================] - 0s 311us/step\n",
      "273/273 [==============================] - 0s 320us/step\n",
      "273/273 [==============================] - 0s 318us/step\n",
      "273/273 [==============================] - 0s 305us/step\n",
      "273/273 [==============================] - 0s 314us/step\n",
      "273/273 [==============================] - 0s 320us/step\n",
      "273/273 [==============================] - 0s 429us/step\n",
      "273/273 [==============================] - 0s 364us/step\n",
      "273/273 [==============================] - 0s 335us/step\n",
      "273/273 [==============================] - 0s 851us/step\n",
      "273/273 [==============================] - 0s 406us/step\n",
      "273/273 [==============================] - 0s 313us/step\n",
      "273/273 [==============================] - 0s 350us/step\n",
      "273/273 [==============================] - 0s 311us/step\n",
      "273/273 [==============================] - 0s 317us/step\n",
      "273/273 [==============================] - 0s 317us/step\n",
      "273/273 [==============================] - 0s 315us/step\n",
      "273/273 [==============================] - 0s 310us/step\n",
      "273/273 [==============================] - 0s 312us/step\n",
      "273/273 [==============================] - 0s 319us/step\n",
      "273/273 [==============================] - 0s 311us/step\n",
      "273/273 [==============================] - 0s 319us/step\n",
      "273/273 [==============================] - 0s 320us/step\n",
      "273/273 [==============================] - 0s 318us/step\n",
      "273/273 [==============================] - 0s 311us/step\n",
      "273/273 [==============================] - 0s 377us/step\n",
      "273/273 [==============================] - 0s 317us/step\n",
      "273/273 [==============================] - 0s 312us/step\n",
      "273/273 [==============================] - 0s 322us/step\n",
      "273/273 [==============================] - 0s 312us/step\n",
      "273/273 [==============================] - 0s 323us/step\n",
      "273/273 [==============================] - 0s 315us/step\n",
      "273/273 [==============================] - 0s 316us/step\n",
      "273/273 [==============================] - 0s 314us/step\n",
      "273/273 [==============================] - 0s 315us/step\n",
      "273/273 [==============================] - 0s 315us/step\n",
      "273/273 [==============================] - 0s 326us/step\n",
      "273/273 [==============================] - 0s 309us/step\n",
      "273/273 [==============================] - 0s 303us/step\n",
      "273/273 [==============================] - 0s 316us/step\n",
      "273/273 [==============================] - 0s 320us/step\n",
      "273/273 [==============================] - 0s 307us/step\n",
      "273/273 [==============================] - 0s 320us/step\n",
      "273/273 [==============================] - 0s 308us/step\n",
      "273/273 [==============================] - 0s 321us/step\n",
      "273/273 [==============================] - 0s 310us/step\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Dropout\n",
    "from keras.models import load_model\n",
    "from keras import backend as K\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Assuming the model is already trained with dropout layers\n",
    "\n",
    "# Function to enable dropout at inference time\n",
    "def predict_with_dropout(model, input_data, n_iterations=100):\n",
    "    predictions = []\n",
    "    for _ in range(n_iterations):\n",
    "        predictions.append(model.predict(input_data))\n",
    "    return np.array(predictions)\n",
    "\n",
    "# Using the function to make predictions with dropout\n",
    "test_X_lstm = np.reshape(test_X, (test_X.shape[0], 1, test_X.shape[1]))\n",
    "predictions = predict_with_dropout(model, test_X_lstm)\n",
    "\n",
    "# Calculate quantiles from predictions\n",
    "quantiles = np.quantile(predictions, [0.025, 0.25, 0.5, 0.75, 0.975], axis=0)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-13T14:05:25.675595Z",
     "start_time": "2023-12-13T14:05:11.963866Z"
    }
   },
   "id": "dc6b8456c90837aa"
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'head'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[46], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mquantiles\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mhead\u001B[49m()\n",
      "\u001B[0;31mAttributeError\u001B[0m: 'numpy.ndarray' object has no attribute 'head'"
     ]
    }
   ],
   "source": [
    "quantiles.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-13T14:07:53.928234Z",
     "start_time": "2023-12-13T14:07:53.844818Z"
    }
   },
   "id": "17a57d15621af3f8"
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Must pass 2-d input. shape=(1, 8715, 5)",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[44], line 7\u001B[0m\n\u001B[1;32m      4\u001B[0m quantile_levels \u001B[38;5;241m=\u001B[39m [\u001B[38;5;241m0.025\u001B[39m, \u001B[38;5;241m0.25\u001B[39m, \u001B[38;5;241m0.5\u001B[39m, \u001B[38;5;241m0.75\u001B[39m, \u001B[38;5;241m0.975\u001B[39m]\n\u001B[1;32m      6\u001B[0m \u001B[38;5;66;03m# Creating DataFrame\u001B[39;00m\n\u001B[0;32m----> 7\u001B[0m quantile_df \u001B[38;5;241m=\u001B[39m \u001B[43mpd\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mDataFrame\u001B[49m\u001B[43m(\u001B[49m\u001B[43mquantiles\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mT\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcolumns\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m[\u001B[49m\u001B[38;5;124;43mf\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mq\u001B[39;49m\u001B[38;5;132;43;01m{\u001B[39;49;00m\u001B[38;5;28;43mint\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mq\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m100\u001B[39;49m\u001B[43m)\u001B[49m\u001B[38;5;132;43;01m}\u001B[39;49;00m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mq\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mquantile_levels\u001B[49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      8\u001B[0m quantile_df[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mhorizon\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m time_horizons\n\u001B[1;32m      9\u001B[0m quantile_df[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mforecast_date\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mto_datetime(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtoday\u001B[39m\u001B[38;5;124m'\u001B[39m)\u001B[38;5;241m.\u001B[39mstrftime(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m%\u001B[39m\u001B[38;5;124mY-\u001B[39m\u001B[38;5;124m%\u001B[39m\u001B[38;5;124mm-\u001B[39m\u001B[38;5;132;01m%d\u001B[39;00m\u001B[38;5;124m'\u001B[39m)\n",
      "File \u001B[0;32m~/anaconda3/envs/Forecasting_Challenge_2/lib/python3.9/site-packages/pandas/core/frame.py:785\u001B[0m, in \u001B[0;36mDataFrame.__init__\u001B[0;34m(self, data, index, columns, dtype, copy)\u001B[0m\n\u001B[1;32m    774\u001B[0m         mgr \u001B[38;5;241m=\u001B[39m dict_to_mgr(\n\u001B[1;32m    775\u001B[0m             \u001B[38;5;66;03m# error: Item \"ndarray\" of \"Union[ndarray, Series, Index]\" has no\u001B[39;00m\n\u001B[1;32m    776\u001B[0m             \u001B[38;5;66;03m# attribute \"name\"\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    782\u001B[0m             copy\u001B[38;5;241m=\u001B[39m_copy,\n\u001B[1;32m    783\u001B[0m         )\n\u001B[1;32m    784\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 785\u001B[0m         mgr \u001B[38;5;241m=\u001B[39m \u001B[43mndarray_to_mgr\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    786\u001B[0m \u001B[43m            \u001B[49m\u001B[43mdata\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    787\u001B[0m \u001B[43m            \u001B[49m\u001B[43mindex\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    788\u001B[0m \u001B[43m            \u001B[49m\u001B[43mcolumns\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    789\u001B[0m \u001B[43m            \u001B[49m\u001B[43mdtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdtype\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    790\u001B[0m \u001B[43m            \u001B[49m\u001B[43mcopy\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcopy\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    791\u001B[0m \u001B[43m            \u001B[49m\u001B[43mtyp\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmanager\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    792\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    794\u001B[0m \u001B[38;5;66;03m# For data is list-like, or Iterable (will consume into list)\u001B[39;00m\n\u001B[1;32m    795\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m is_list_like(data):\n",
      "File \u001B[0;32m~/anaconda3/envs/Forecasting_Challenge_2/lib/python3.9/site-packages/pandas/core/internals/construction.py:314\u001B[0m, in \u001B[0;36mndarray_to_mgr\u001B[0;34m(values, index, columns, dtype, copy, typ)\u001B[0m\n\u001B[1;32m    308\u001B[0m     _copy \u001B[38;5;241m=\u001B[39m (\n\u001B[1;32m    309\u001B[0m         copy_on_sanitize\n\u001B[1;32m    310\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m (dtype \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mor\u001B[39;00m astype_is_view(values\u001B[38;5;241m.\u001B[39mdtype, dtype))\n\u001B[1;32m    311\u001B[0m         \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[1;32m    312\u001B[0m     )\n\u001B[1;32m    313\u001B[0m     values \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39marray(values, copy\u001B[38;5;241m=\u001B[39m_copy)\n\u001B[0;32m--> 314\u001B[0m     values \u001B[38;5;241m=\u001B[39m \u001B[43m_ensure_2d\u001B[49m\u001B[43m(\u001B[49m\u001B[43mvalues\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    316\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    317\u001B[0m     \u001B[38;5;66;03m# by definition an array here\u001B[39;00m\n\u001B[1;32m    318\u001B[0m     \u001B[38;5;66;03m# the dtypes will be coerced to a single dtype\u001B[39;00m\n\u001B[1;32m    319\u001B[0m     values \u001B[38;5;241m=\u001B[39m _prep_ndarraylike(values, copy\u001B[38;5;241m=\u001B[39mcopy_on_sanitize)\n",
      "File \u001B[0;32m~/anaconda3/envs/Forecasting_Challenge_2/lib/python3.9/site-packages/pandas/core/internals/construction.py:592\u001B[0m, in \u001B[0;36m_ensure_2d\u001B[0;34m(values)\u001B[0m\n\u001B[1;32m    590\u001B[0m     values \u001B[38;5;241m=\u001B[39m values\u001B[38;5;241m.\u001B[39mreshape((values\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m0\u001B[39m], \u001B[38;5;241m1\u001B[39m))\n\u001B[1;32m    591\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m values\u001B[38;5;241m.\u001B[39mndim \u001B[38;5;241m!=\u001B[39m \u001B[38;5;241m2\u001B[39m:\n\u001B[0;32m--> 592\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mMust pass 2-d input. shape=\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mvalues\u001B[38;5;241m.\u001B[39mshape\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m    593\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m values\n",
      "\u001B[0;31mValueError\u001B[0m: Must pass 2-d input. shape=(1, 8715, 5)"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# Example time horizons in hours\n",
    "time_horizons = [36, 40, 44, 60, 64, 68]\n",
    "quantile_levels = [0.025, 0.25, 0.5, 0.75, 0.975]\n",
    "\n",
    "# Creating DataFrame\n",
    "quantile_df = pd.DataFrame(quantiles.T, columns=[f'q{int(q*100)}' for q in quantile_levels])\n",
    "quantile_df['horizon'] = time_horizons\n",
    "quantile_df['forecast_date'] = pd.to_datetime('today').strftime('%Y-%m-%d')\n",
    "quantile_df['target'] = 'energy'\n",
    "\n",
    "# Rearranging columns\n",
    "quantile_df = quantile_df[['forecast_date', 'target', 'horizon'] + [f'q{int(q*100)}' for q in quantile_levels]]\n",
    "\n",
    "# Exporting to CSV\n",
    "quantile_df.to_csv('energy_forecast_quantiles.csv', index=False)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-13T14:07:09.944922Z",
     "start_time": "2023-12-13T14:07:09.780566Z"
    }
   },
   "id": "7a18b4320c1d0c86"
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [],
   "source": [
    "# Define the specific horizons (in number of time steps)\n",
    "# Example: if each time step is 1 hour, for 36, 40, 44 hours ahead\n",
    "horizons = [35, 39, 43, 59, 63, 67]  # Zero-based indexing\n",
    "\n",
    "# Extract the relevant quantiles for these horizons\n",
    "# This assumes the second dimension of 'quantiles' corresponds to different horizons\n",
    "selected_quantiles = quantiles[:, horizons, 0]  # Shape: (num_quantiles, len(horizons))\n",
    "\n",
    "# Creating the DataFrame\n",
    "quantile_df = pd.DataFrame(selected_quantiles.T, columns=[f'q{int(q*100)}' for q in [0.025, 0.25, 0.5, 0.75, 0.975]])\n",
    "quantile_df['horizon'] = [f'{h+1} hour' for h in horizons]  # h+1 because we subtracted 1 earlier\n",
    "quantile_df['forecast_date'] = pd.to_datetime('today').strftime('%Y-%m-%d')\n",
    "quantile_df['target'] = 'energy'\n",
    "\n",
    "# Reordering the columns for clarity\n",
    "quantile_df = quantile_df[['forecast_date', 'target', 'horizon'] + [f'q{int(q*100)}' for q in [0.025, 0.25, 0.5, 0.75, 0.975]]]\n",
    "\n",
    "# Exporting to CSV\n",
    "quantile_df.to_csv('energy_forecast_quantiles.csv', index=False)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-13T14:08:55.336196Z",
     "start_time": "2023-12-13T14:08:55.334684Z"
    }
   },
   "id": "1236a79e1c76515"
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [
    {
     "data": {
      "text/plain": "  forecast_date  target  horizon         q2        q25        q50        q75  \\\n0    2023-12-13  energy  36 hour  56.596985  56.596985  56.596985  56.596985   \n1    2023-12-13  energy  40 hour  48.123363  48.123363  48.123363  48.123363   \n2    2023-12-13  energy  44 hour  49.314907  49.314907  49.314907  49.314907   \n3    2023-12-13  energy  60 hour  54.060722  54.060722  54.060722  54.060722   \n4    2023-12-13  energy  64 hour  46.440258  46.440258  46.440258  46.440258   \n5    2023-12-13  energy  68 hour  46.161129  46.161129  46.161129  46.161129   \n\n         q97  \n0  56.596985  \n1  48.123363  \n2  49.314907  \n3  54.060722  \n4  46.440258  \n5  46.161129  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>forecast_date</th>\n      <th>target</th>\n      <th>horizon</th>\n      <th>q2</th>\n      <th>q25</th>\n      <th>q50</th>\n      <th>q75</th>\n      <th>q97</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2023-12-13</td>\n      <td>energy</td>\n      <td>36 hour</td>\n      <td>56.596985</td>\n      <td>56.596985</td>\n      <td>56.596985</td>\n      <td>56.596985</td>\n      <td>56.596985</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2023-12-13</td>\n      <td>energy</td>\n      <td>40 hour</td>\n      <td>48.123363</td>\n      <td>48.123363</td>\n      <td>48.123363</td>\n      <td>48.123363</td>\n      <td>48.123363</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2023-12-13</td>\n      <td>energy</td>\n      <td>44 hour</td>\n      <td>49.314907</td>\n      <td>49.314907</td>\n      <td>49.314907</td>\n      <td>49.314907</td>\n      <td>49.314907</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2023-12-13</td>\n      <td>energy</td>\n      <td>60 hour</td>\n      <td>54.060722</td>\n      <td>54.060722</td>\n      <td>54.060722</td>\n      <td>54.060722</td>\n      <td>54.060722</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2023-12-13</td>\n      <td>energy</td>\n      <td>64 hour</td>\n      <td>46.440258</td>\n      <td>46.440258</td>\n      <td>46.440258</td>\n      <td>46.440258</td>\n      <td>46.440258</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>2023-12-13</td>\n      <td>energy</td>\n      <td>68 hour</td>\n      <td>46.161129</td>\n      <td>46.161129</td>\n      <td>46.161129</td>\n      <td>46.161129</td>\n      <td>46.161129</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quantile_df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-13T14:09:04.442687Z",
     "start_time": "2023-12-13T14:09:04.425326Z"
    }
   },
   "id": "c48dbc6493413289"
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'method_descriptor' object has no attribute 'today'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[55], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43menergy_quantile_regression\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43menergy_quantile_regression\u001B[49m\u001B[43m(\u001B[49m\u001B[43menergydata\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/PycharmProjects/probabilistic-forecasting-challenge/models/energy/energy_quantile_regression.py:10\u001B[0m, in \u001B[0;36menergy_quantile_regression\u001B[0;34m(df, date_str)\u001B[0m\n\u001B[1;32m      8\u001B[0m     df \u001B[38;5;241m=\u001B[39m get_energy\u001B[38;5;241m.\u001B[39mget()\n\u001B[1;32m      9\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m date_str\u001B[38;5;241m==\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m---> 10\u001B[0m     date_str \u001B[38;5;241m=\u001B[39m \u001B[43mdatetime\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdate\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtoday\u001B[49m()\n\u001B[1;32m     11\u001B[0m \u001B[38;5;66;03m# Define the lead times\u001B[39;00m\n\u001B[1;32m     12\u001B[0m horizons_def \u001B[38;5;241m=\u001B[39m [\u001B[38;5;241m36\u001B[39m, \u001B[38;5;241m40\u001B[39m, \u001B[38;5;241m44\u001B[39m, \u001B[38;5;241m60\u001B[39m, \u001B[38;5;241m64\u001B[39m, \u001B[38;5;241m68\u001B[39m]\n",
      "\u001B[0;31mAttributeError\u001B[0m: 'method_descriptor' object has no attribute 'today'"
     ]
    }
   ],
   "source": [
    "energy_quantile_regression.energy_quantile_regression(energydata)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-13T18:12:40.294926Z",
     "start_time": "2023-12-13T18:12:40.226236Z"
    }
   },
   "id": "febd05a0ddf13eed"
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [],
   "source": [
    "from models.energy import energy_quantile_regression"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-13T18:12:37.998950Z",
     "start_time": "2023-12-13T18:12:37.993089Z"
    }
   },
   "id": "d3194e63be674850"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "from models.energy import energy_LSTM"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-05T07:46:46.116852Z",
     "start_time": "2024-01-05T07:46:43.016472Z"
    }
   },
   "id": "83878be54b2d1885"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-05 08:46:46.959820: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2024-01-05 08:46:46.961037: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2024-01-05 08:46:46.961748: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2024-01-05 08:46:47.020162: W tensorflow/tsl/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n",
      "2024-01-05 08:46:47.148027: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2024-01-05 08:46:47.148896: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2024-01-05 08:46:47.149706: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2024-01-05 08:46:47.402528: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2024-01-05 08:46:47.403418: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2024-01-05 08:46:47.404307: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1103/1103 [==============================] - 2s 901us/step - loss: 1311.7590\n",
      "Epoch 2/10\n",
      "1103/1103 [==============================] - 1s 869us/step - loss: 169.5422\n",
      "Epoch 3/10\n",
      "1103/1103 [==============================] - 1s 854us/step - loss: 96.7665\n",
      "Epoch 4/10\n",
      "1103/1103 [==============================] - 1s 861us/step - loss: 96.0562\n",
      "Epoch 5/10\n",
      "1103/1103 [==============================] - 1s 863us/step - loss: 96.0247\n",
      "Epoch 6/10\n",
      "1103/1103 [==============================] - 1s 862us/step - loss: 96.0018\n",
      "Epoch 7/10\n",
      "1103/1103 [==============================] - 1s 890us/step - loss: 95.9794\n",
      "Epoch 8/10\n",
      "1103/1103 [==============================] - 1s 1ms/step - loss: 95.9848\n",
      "Epoch 9/10\n",
      "1103/1103 [==============================] - 1s 875us/step - loss: 95.9773\n",
      "Epoch 10/10\n",
      "1103/1103 [==============================] - 1s 863us/step - loss: 95.9690\n",
      "1/1 [==============================] - 0s 262ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-05 08:46:58.143471: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2024-01-05 08:46:58.144224: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2024-01-05 08:46:58.145100: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"
     ]
    }
   ],
   "source": [
    "df_LSTM=energy_LSTM.build_and_forecast_lstm(energydata, '2024-01-05')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-05T07:46:58.249129Z",
     "start_time": "2024-01-05T07:46:46.813760Z"
    }
   },
   "id": "1282abf6574e80be"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "  forecast_date  target  horizon     q0.025      q0.25       q0.5      q0.75  \\\n0    2024-01-05  energy  36 hour  56.096050  56.096416  56.096115  56.096184   \n1    2024-01-05  energy  40 hour  56.097294  56.097733  56.097378  56.097458   \n2    2024-01-05  energy  44 hour  56.097637  56.098091  56.097725  56.097801   \n3    2024-01-05  energy  60 hour  56.097008  56.097431  56.097092  56.097160   \n4    2024-01-05  energy  64 hour  56.097572  56.098003  56.097652  56.097725   \n5    2024-01-05  energy  68 hour  56.097713  56.098175  56.097805  56.097893   \n\n      q0.975  \n0  56.096355  \n1  56.097645  \n2  56.097996  \n3  56.097355  \n4  56.097931  \n5  56.098080  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>forecast_date</th>\n      <th>target</th>\n      <th>horizon</th>\n      <th>q0.025</th>\n      <th>q0.25</th>\n      <th>q0.5</th>\n      <th>q0.75</th>\n      <th>q0.975</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2024-01-05</td>\n      <td>energy</td>\n      <td>36 hour</td>\n      <td>56.096050</td>\n      <td>56.096416</td>\n      <td>56.096115</td>\n      <td>56.096184</td>\n      <td>56.096355</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2024-01-05</td>\n      <td>energy</td>\n      <td>40 hour</td>\n      <td>56.097294</td>\n      <td>56.097733</td>\n      <td>56.097378</td>\n      <td>56.097458</td>\n      <td>56.097645</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2024-01-05</td>\n      <td>energy</td>\n      <td>44 hour</td>\n      <td>56.097637</td>\n      <td>56.098091</td>\n      <td>56.097725</td>\n      <td>56.097801</td>\n      <td>56.097996</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2024-01-05</td>\n      <td>energy</td>\n      <td>60 hour</td>\n      <td>56.097008</td>\n      <td>56.097431</td>\n      <td>56.097092</td>\n      <td>56.097160</td>\n      <td>56.097355</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2024-01-05</td>\n      <td>energy</td>\n      <td>64 hour</td>\n      <td>56.097572</td>\n      <td>56.098003</td>\n      <td>56.097652</td>\n      <td>56.097725</td>\n      <td>56.097931</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>2024-01-05</td>\n      <td>energy</td>\n      <td>68 hour</td>\n      <td>56.097713</td>\n      <td>56.098175</td>\n      <td>56.097805</td>\n      <td>56.097893</td>\n      <td>56.098080</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_LSTM"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-05T07:46:58.261892Z",
     "start_time": "2024-01-05T07:46:58.254723Z"
    }
   },
   "id": "aef821bd20f912d"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "22f8d36eaa6fd1e0"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
